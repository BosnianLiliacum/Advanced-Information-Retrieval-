Post Title: I built Plano(A3B). Offers &lt;200 ms latency with frontier model performance for multi-agent systems
Author: AdditionalWeb107
Score: 12
URL: https://i.redd.it/ucrxhaecmh9g1.png
Number of comments: 0
Created UTC: 1766728337.0

Post Content:
Hi everyone — I’m on the Katanemo research team. Today we’re thrilled to launch Plano-Orchestrator, a new family of LLMs built for fast multi-agent orchestration.

What do these new LLMs do? given a user request and the conversation context, Plano-Orchestrator decides which agent(s) should handle the request and in what sequence. In other words, it acts as the supervisor agent in a multi-agent system. Designed for multi-domain scenarios, it works well across general chat, coding tasks, and long, multi-turn conversations, while staying efficient enough for low-latency production deployments.

Why did we built this? Our applied research is focused on helping teams deliver agents safely and efficiently, with better real-world performance and latency — the kind of “glue work” that usually sits outside any single agent’s core product logic.

Plano-Orchestrator is integrated into Plano, our models-native proxy and dataplane for agents. Hope you enjoy it — and we’d love feedback from anyone building multi-agent systems

Learn more about the LLMs [here](https://huggingface.co/collections/katanemo/plano-orchestrator)  
About our open source project: [https://github.com/katanemo/plano](https://github.com/katanemo/plano)  
And about our research: [https://planoai.dev/research](https://planoai.dev/research)


Top 0 comments: